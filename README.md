# HO3V: The Dataset for Arbitrary View Action Recognition via Transfer Dictionary Learning on Synthetic Training Data

![teaser](https://user-images.githubusercontent.com/77708790/146571925-dc3b1e8c-d7dd-42e9-9103-1aa4e0bd5c5d.png)

<p>We present the HO3V datasets for arbitrary view action recognition, as described in the paper <a href="http://hubertshum.com/pbl_icra2016action.htm">Arbitrary View Action Recognition via Transfer Dictionary Learning on Synthetic Training Data</a>. HO3V includes 2 sub-datasets tailored for N-UCLA and IXMAS, each consisting of a set of AVI videos and BVH motion files.

The AVI video files can be viewed by a video player. The BVH motion data can be visualised using Autodesk MotionBuilder. <a href="https://www.youtube.com/playlist?list=PLtv0q3KQ5a9rKTl3v4qwmTY2VaXemwPu8">YouTube tutorials</a> are available.

<h2>Reference</h2>
<p>By using this dataset, you agree to cite the following research publication in all related project documents/publications:</p>
<p ">Jingtian Zhang, Lining Zhang, Hubert P. H. Shum and Ling Shao, "<a href="http://hubertshum.com/pbl_icra2016action.htm">Arbitrary View Action Recognition via Transfer Dictionary Learning on Synthetic Training Data</a>," in Proceedings of the 2016 IEEE International Conference on Robotics and Automation (ICRA), 2016.</p>


